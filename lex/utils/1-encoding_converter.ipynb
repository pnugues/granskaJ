{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the lexical resources\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lexical resources of _Granska_ are in the Latin 1, or possibly Latin 9, encodings. These are legacy codes, no longer supported by many programs, and for Latin 1, very poorly designed. We convert them into the more recent Unicode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, dirname, exists\n",
    "from os import mkdir\n",
    "from urllib.request import urlopen\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The resource names and locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the resources in Viggo Kann's GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_url = 'https://raw.githubusercontent.com/viggokann/granska/willes/lex/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `morfs` folder and its files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morfs_folder = 'morfs/'\n",
    "morfs_files = ['cw', 'cwt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tags` folder and its files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_folder = 'tags/'\n",
    "tags_files = ['ct', 'ctm', 'ctt', 'cttt', 'features', 'taginfo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally `words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_folder = 'words/'\n",
    "words_files = ['bitransitivaverb', 'compound-begin-ok.w', 'compound-end-stop.w',\n",
    "              'cw', 'cwtl', 'feminina', 'foreign.w', 'inflection.lex', 'inflection.rules',\n",
    "              'intransitivaverb', 'opt_space_words', 'spellNotOK', 'spellOK']\n",
    "words_problematic_files = ['cw', 'cwtl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the converted files in this folder. If it does not exist, we create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = '../../lex/'\n",
    "if not exists(dest_folder):\n",
    "    mkdir(dest_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving and converting the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume the original files are in Latin-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `morfs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `morfs` folder. If it does not exist, we create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(dest_folder + morfs_folder):\n",
    "    mkdir(dest_folder + morfs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve and convert the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in morfs_files:\n",
    "    data = urlopen(src_url + morfs_folder + file).read().decode('latin-1')\n",
    "    open(dest_folder + morfs_folder + file, 'w', encoding='utf-8').write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same thing for `tags`. The folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(dest_folder + tags_folder):\n",
    "    mkdir(dest_folder + tags_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tags_files:\n",
    "    data = urlopen(src_url + tags_folder + file).read().decode('latin-1')\n",
    "    open(dest_folder + tags_folder + file, 'w', encoding='utf-8').write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `words`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally `words`. The folder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(dest_folder + words_folder):\n",
    "    mkdir(dest_folder + words_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in words_files:\n",
    "    data = urlopen(src_url + words_folder + file).read().decode('latin-1')\n",
    "    open(dest_folder + words_folder + file, 'w', encoding='utf-8').write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting the encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two files in the `words` folder, `cw` and `cwtl`, contain spurious codes corresponding to the bell command `\\a`. We remove them as they are not translated in the UTF-8 file and result in a null string. This is the new loop that discards lines with words only consisting of such control characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in words_problematic_files:\n",
    "    data = urlopen(src_url + words_folder + file).read().decode('latin-1')\n",
    "    lines = re.split('[\\r\\n]+', data)\n",
    "    lines = [line for line in lines \n",
    "             if len(re.split('\\t+', line)) > 1 \n",
    "             and not re.match('\\\\a$', \n",
    "                          re.split('\\t+', line)[1])]\n",
    "    data = '\\n'.join(lines)\n",
    "    open(dest_folder + words_folder + file, 'w', encoding='utf-8').write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
